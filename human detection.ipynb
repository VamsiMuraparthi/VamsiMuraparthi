{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a84627b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working model for human detection\n",
    "import numpy as np\n",
    "import cv2\n",
    "import datetime\n",
    "\n",
    "count = 0\n",
    "\n",
    "# initialize the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# open webcam video stream\n",
    "cap = cv2.VideoCapture(\"E:\\proj\\in1.mp4\")\n",
    "\n",
    "# the output will be written to output.avi\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'MJPG'),15.,(640, 480))\n",
    "\n",
    "while (True):\n",
    "    # Capturing frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n",
    "    \n",
    "    dt = str(datetime.datetime.now())\n",
    "    \n",
    "    frame = cv2.putText(frame, dt,\n",
    "                            (400, 900),\n",
    "                            font, 1,\n",
    "                            (0, 0, 255),\n",
    "                            4, cv2.LINE_8)\n",
    "\n",
    "    # resizing for faster detection\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    # using a greyscale picture, also for faster detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # detect people in the image\n",
    "    # returns the bounding boxes for the detected objects\n",
    "    boxes, weights = hog.detectMultiScale(frame, winStride=(8, 8))\n",
    "\n",
    "    boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "\n",
    "    for (xA, yA, xB, yB) in boxes:\n",
    "        # display the detected boxes in the colour picture\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB),\n",
    "                      (0, 255, 0), 2)\n",
    "      \n",
    "\n",
    "                \n",
    "    # Write the output video\n",
    "    out.write(frame.astype('uint8'))\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# and release the output\n",
    "out.release()\n",
    "# finally, close the window\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b4aaeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working model for human detection\n",
    "import numpy as np\n",
    "import cv2\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count = 0\n",
    "\n",
    "# initialize the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# open webcam video stream\n",
    "cap = cv2.VideoCapture(\"E:\\proj\\in1.mp4\")\n",
    "\n",
    "# the output will be written to output.avi\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'MJPG'),15.,(640, 480))\n",
    "\n",
    "while (True):\n",
    "    # Capturing frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n",
    "    \n",
    "    dt = str(datetime.datetime.now())\n",
    "    \n",
    "    frame = cv2.putText(frame, dt,\n",
    "                            (400, 900),\n",
    "                            font, 1,\n",
    "                            (0, 0, 255),\n",
    "                            4, cv2.LINE_8)\n",
    "\n",
    "    # resizing for faster detection\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    # using a greyscale picture, also for faster detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # detect people in the image\n",
    "    # returns the bounding boxes for the detected objects\n",
    "    boxes, weights = hog.detectMultiScale(frame, winStride=(8, 8))\n",
    "\n",
    "    boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "\n",
    "    for (xA, yA, xB, yB) in boxes:\n",
    "        # display the detected boxes in the colour picture\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB),\n",
    "                      (0, 255, 0), 2)\n",
    "        # Import libraries\n",
    "        blur = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "        canny = cv2.Canny(blur, 30, 150, 3)\n",
    "        dilated = cv2.dilate(canny, (1, 1), iterations=0)\n",
    "\n",
    "        (cnt, hierarchy) = cv2.findContours(\n",
    "            dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        cv2.drawContours(rgb, cnt, -10, (0, 255, 0), 5)\n",
    "        count = len(cnt)\n",
    "        cn = str(count)\n",
    "        frame = cv2.putText(frame, cn,\n",
    "                            (550, 50),\n",
    "                            font, 1,\n",
    "                            (0, 0, 255),\n",
    "                            4, cv2.LINE_8)\n",
    "        \n",
    "        \n",
    "               \n",
    "    # Write the output video\n",
    "    out.write(frame.astype('uint8'))\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# and release the output\n",
    "out.release()\n",
    "# finally, close the window\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97160692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f96c00ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working model for human detection\n",
    "import numpy as np\n",
    "import cv2\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count = 0\n",
    "\n",
    "# initialize the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# open webcam video stream\n",
    "cap = cv2.VideoCapture(\"E:\\proj\\in1.mp4\")\n",
    "\n",
    "# the output will be written to output.avi\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'MJPG'),15.,(640, 480))\n",
    "\n",
    "while (True):\n",
    "    # Capturing frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n",
    "    \n",
    "    dt = str(datetime.datetime.now())\n",
    "    \n",
    "    frame = cv2.putText(frame, dt,\n",
    "                            (400, 900),\n",
    "                            font, 1,\n",
    "                            (0, 0, 255),\n",
    "                            4, cv2.LINE_8)\n",
    "\n",
    "    # resizing for faster detection\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    # using a greyscale picture, also for faster detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # detect people in the image\n",
    "    # returns the bounding boxes for the detected objects\n",
    "    boxes, weights = hog.detectMultiScale(frame, winStride=(8, 8))\n",
    "\n",
    "    boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "\n",
    "    for (xA, yA, xB, yB) in boxes:\n",
    "        # display the detected boxes in the colour picture\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB),\n",
    "                      (0, 255, 0), 2)\n",
    "        # Import libraries\n",
    "        blur = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "        canny = cv2.Canny(blur, 30, 150, 3)\n",
    "        dilated = cv2.dilate(canny, (1, 1), iterations=0)\n",
    "\n",
    "        (cnt, hierarchy) = cv2.findContours(\n",
    "            dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        cv2.drawContours(rgb, cnt, -10, (0, 255, 0), 5)\n",
    "        count = len(cnt)\n",
    "        cn = str(count)\n",
    "        frame = cv2.putText(frame, cn,\n",
    "                            (550, 50),\n",
    "                            font, 1,\n",
    "                            (0, 0, 255),\n",
    "                            4, cv2.LINE_8)\n",
    "        \n",
    "        \n",
    "               \n",
    "    # Write the output video\n",
    "    out.write(frame.astype('uint8'))\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# and release the output\n",
    "out.release()\n",
    "# finally, close the window\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b855082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "from numpy.lib.polynomial import poly\n",
    "import datetime\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "# initialize the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# open webcam video stream\n",
    "cap = cv2.VideoCapture(\"E:\\proj\\in1.mp4\")\n",
    "\n",
    "# the output will be written to output.avi\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'MJPG'),15.,(640, 480))\n",
    "\n",
    "while (True):\n",
    "    # Capturing frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n",
    "    \n",
    "    dt = str(datetime.datetime.now())\n",
    "    \n",
    "    frame = cv2.putText(frame, dt,\n",
    "                            (400, 900),\n",
    "                            font, 1,\n",
    "                            (0, 0, 255),\n",
    "                            4, cv2.LINE_8)\n",
    "\n",
    "    # resizing for faster detection\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    # using a greyscale picture, also for faster detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # detect people in the image\n",
    "    # returns the bounding boxes for the detected objects\n",
    "    boxes, weights = hog.detectMultiScale(frame, winStride=(8, 8))\n",
    "\n",
    "    boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "\n",
    "    for (xA, yA, xB, yB) in boxes:\n",
    "        # display the detected boxes in the colour picture\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB),\n",
    "                      (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "                \n",
    "    # Write the output video\n",
    "    out.write(frame.astype('uint8'))\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# and release the output\n",
    "out.release()\n",
    "# finally, close the window\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "250c18fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# producing negative values \n",
    "import numpy as np\n",
    "import cv2\n",
    "import datetime\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "# initialize the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# open webcam video stream\n",
    "cap = cv2.VideoCapture(\"E:\\proj\\in1.mp4\")\n",
    "\n",
    "# the output will be written to output.avi\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'MJPG'),15.,(640, 480))\n",
    "\n",
    "while (True):\n",
    "    # Capturing frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n",
    "    \n",
    "    dt = str(datetime.datetime.now())\n",
    "    \n",
    "    frame = cv2.putText(frame, dt,\n",
    "                            (400, 900),\n",
    "                            font, 1,\n",
    "                            (0, 0, 255),\n",
    "                            4, cv2.LINE_8)\n",
    "\n",
    "    # resizing for faster detection\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    # using a greyscale picture, also for faster detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # detect people in the image\n",
    "    # returns the bounding boxes for the detected objects\n",
    "    boxes, weights = hog.detectMultiScale(frame, winStride=(8, 8))\n",
    "\n",
    "    boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "\n",
    "    for (xA, yA, xB, yB) in boxes:\n",
    "        # display the detected boxes in the colour picture\n",
    "        rec = cv2.rectangle(frame, (xA, yA), (xB, yB),\n",
    "                      (0, 255, 0), 2)\n",
    "      \n",
    "\n",
    "        if (rec.all() == 1):\n",
    "            count = count+1\n",
    "        else :\n",
    "            count = count-1\n",
    "        cn = str(count)\n",
    "        frame = cv2.putText(frame, cn,\n",
    "                            (550, 50),\n",
    "                            font, 1,\n",
    "                            (0, 0, 255),\n",
    "                            4, cv2.LINE_8)\n",
    "\n",
    "    # Write the output video\n",
    "    out.write(frame.astype('uint8'))\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# and release the output\n",
    "out.release()\n",
    "# finally, close the window\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaad846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
